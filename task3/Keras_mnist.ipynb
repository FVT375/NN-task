{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Activation, MaxPool2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Images fed into this model are 512 x 512 pixels with 3 channels\n",
    "img_shape = (28,28,1)\n",
    "\n",
    "# Set up model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer with 3, 3 by 3 filters and a stride size of 1\n",
    "# Set padding so that input size equals output size\n",
    "model.add(Conv2D(6,2,input_shape=img_shape))\n",
    "# Add relu activation to the layer \n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 6)         30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27, 27, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1014)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10150     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 10,180\n",
      "Trainable params: 10,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.expand_dims(x_test,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 4.2842 - acc: 0.7067 - val_loss: 0.5065 - val_acc: 0.9262\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.2539 - acc: 0.9419 - val_loss: 0.1528 - val_acc: 0.9543\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1401 - acc: 0.9582 - val_loss: 0.1356 - val_acc: 0.9592\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.1191 - acc: 0.9644 - val_loss: 0.1131 - val_acc: 0.9650\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1052 - acc: 0.9669 - val_loss: 0.1134 - val_acc: 0.9648\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0944 - acc: 0.9705 - val_loss: 0.1146 - val_acc: 0.9651\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0877 - acc: 0.9730 - val_loss: 0.1136 - val_acc: 0.9661\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0798 - acc: 0.9752 - val_loss: 0.1235 - val_acc: 0.9620\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0763 - acc: 0.9762 - val_loss: 0.1012 - val_acc: 0.9699\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0713 - acc: 0.9774 - val_loss: 0.0991 - val_acc: 0.9702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f389ce4d1d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
